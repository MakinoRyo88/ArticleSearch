#!/bin/bash

# å…¨è¨˜äº‹ã®ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆãƒãƒƒãƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# 779è¨˜äº‹ã‚’10è¨˜äº‹ãšã¤ãƒãƒƒãƒå‡¦ç†

set -e

FUNCTION_URL="https://asia-northeast1-seo-optimize-464208.cloudfunctions.net/generate-chunk-embeddings"
BATCH_SIZE=10
TOTAL_ARTICLES=779

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘        ğŸš€ å…¨è¨˜äº‹ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆãƒãƒƒãƒå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“Š è¨­å®š:"
echo "   ç·è¨˜äº‹æ•°: ${TOTAL_ARTICLES}ä»¶"
echo "   ãƒãƒƒãƒã‚µã‚¤ã‚º: ${BATCH_SIZE}ä»¶"
echo "   ç·ãƒãƒƒãƒæ•°: $((($TOTAL_ARTICLES + $BATCH_SIZE - 1) / $BATCH_SIZE))å›"
echo ""

# çµæœã‚’ä¿å­˜
RESULTS_FILE="chunk_generation_results_$(date +%Y%m%d_%H%M%S).log"
echo "ğŸ“ çµæœãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: ${RESULTS_FILE}"
echo ""

# ç¢ºèª
read -p "å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): " confirm
if [[ "$confirm" != "y" && "$confirm" != "Y" ]]; then
    echo "âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ"
    exit 0
fi

echo "" | tee -a "$RESULTS_FILE"
echo "é–‹å§‹æ™‚åˆ»: $(date)" | tee -a "$RESULTS_FILE"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" | tee -a "$RESULTS_FILE"
echo "" | tee -a "$RESULTS_FILE"

# ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
total_processed=0
total_chunks=0
failed_batches=0

# ãƒãƒƒãƒãƒ«ãƒ¼ãƒ—
for offset in $(seq 0 $BATCH_SIZE $((TOTAL_ARTICLES - 1))); do
    batch_num=$(($offset / $BATCH_SIZE + 1))
    total_batches=$((($TOTAL_ARTICLES + $BATCH_SIZE - 1) / $BATCH_SIZE))
    
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" | tee -a "$RESULTS_FILE"
    echo "ğŸ“¦ ãƒãƒƒãƒ ${batch_num}/${total_batches}" | tee -a "$RESULTS_FILE"
    echo "   ã‚ªãƒ•ã‚»ãƒƒãƒˆ: ${offset}" | tee -a "$RESULTS_FILE"
    echo "   é–‹å§‹: $(date +%H:%M:%S)" | tee -a "$RESULTS_FILE"
    
    # APIå‘¼ã³å‡ºã—
    response=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -X POST "$FUNCTION_URL" \
        -H "Content-Type: application/json" \
        -d "{
            \"batch_size\": ${BATCH_SIZE},
            \"force_regenerate\": false,
            \"offset\": ${offset}
        }")
    
    # HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨ãƒœãƒ‡ã‚£ã‚’åˆ†é›¢
    http_status=$(echo "$response" | grep "HTTP_STATUS:" | cut -d: -f2)
    body=$(echo "$response" | sed '/HTTP_STATUS:/d')
    
    # çµæœã‚’è§£æ
    if [[ "$http_status" == "200" ]]; then
        processed=$(echo "$body" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('processed_articles', 0))" 2>/dev/null || echo "0")
        chunks=$(echo "$body" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('generated_chunks', 0))" 2>/dev/null || echo "0")
        
        total_processed=$((total_processed + processed))
        total_chunks=$((total_chunks + chunks))
        
        echo "   âœ… æˆåŠŸ: ${processed}è¨˜äº‹ã€${chunks}ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆ" | tee -a "$RESULTS_FILE"
        echo "   ç´¯è¨ˆ: ${total_processed}è¨˜äº‹ã€${total_chunks}ãƒãƒ£ãƒ³ã‚¯" | tee -a "$RESULTS_FILE"
    else
        echo "   âŒ å¤±æ•—: HTTP ${http_status}" | tee -a "$RESULTS_FILE"
        echo "   Response: ${body}" | tee -a "$RESULTS_FILE"
        failed_batches=$((failed_batches + 1))
        
        # 3å›é€£ç¶šå¤±æ•—ã§åœæ­¢
        if [[ $failed_batches -ge 3 ]]; then
            echo "" | tee -a "$RESULTS_FILE"
            echo "ğŸ’¥ é€£ç¶šå¤±æ•—ãŒ3å›ã«é”ã—ãŸãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™" | tee -a "$RESULTS_FILE"
            break
        fi
    fi
    
    echo "   çµ‚äº†: $(date +%H:%M:%S)" | tee -a "$RESULTS_FILE"
    
    # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆæœ€å¾Œã®ãƒãƒƒãƒä»¥å¤–ï¼‰
    if [[ $offset -lt $((TOTAL_ARTICLES - BATCH_SIZE)) ]]; then
        echo "   â³ å¾…æ©Ÿ: 5ç§’..." | tee -a "$RESULTS_FILE"
        sleep 5
    fi
done

echo "" | tee -a "$RESULTS_FILE"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" | tee -a "$RESULTS_FILE"
echo "ğŸ“Š æœ€çµ‚çµæœ" | tee -a "$RESULTS_FILE"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" | tee -a "$RESULTS_FILE"
echo "   å‡¦ç†ã—ãŸè¨˜äº‹æ•°: ${total_processed}/${TOTAL_ARTICLES}" | tee -a "$RESULTS_FILE"
echo "   ç”Ÿæˆã—ãŸãƒãƒ£ãƒ³ã‚¯æ•°: ${total_chunks}" | tee -a "$RESULTS_FILE"
echo "   å¤±æ•—ã—ãŸãƒãƒƒãƒæ•°: ${failed_batches}" | tee -a "$RESULTS_FILE"
echo "   å®Œäº†ç‡: $(awk "BEGIN {printf \"%.2f\", ($total_processed/$TOTAL_ARTICLES)*100}")%" | tee -a "$RESULTS_FILE"
echo "   çµ‚äº†æ™‚åˆ»: $(date)" | tee -a "$RESULTS_FILE"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" | tee -a "$RESULTS_FILE"
echo "" | tee -a "$RESULTS_FILE"

# BigQueryã§ç¢ºèª
echo "ğŸ” BigQueryã§çµæœã‚’ç¢ºèªä¸­..." | tee -a "$RESULTS_FILE"
bq query --use_legacy_sql=false "
SELECT 
  COUNT(*) as total_chunks,
  COUNT(DISTINCT article_id) as articles_with_chunks,
  AVG(LENGTH(chunk_text)) as avg_chunk_length,
  MIN(LENGTH(chunk_text)) as min_chunk_length,
  MAX(LENGTH(chunk_text)) as max_chunk_length
FROM \`seo-optimize-464208.content_analysis.article_chunks\`
" | tee -a "$RESULTS_FILE"

echo "" | tee -a "$RESULTS_FILE"
echo "âœ… ãƒãƒƒãƒå‡¦ç†å®Œäº†ï¼" | tee -a "$RESULTS_FILE"
echo "ğŸ“ è©³ç´°ãƒ­ã‚°: ${RESULTS_FILE}" | tee -a "$RESULTS_FILE"
